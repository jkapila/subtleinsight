{
  "hash": "1e37e730b9c08dd823cf568fbd31f7f8",
  "result": {
    "markdown": "---\ntitle: \"A flow to test your hypothesis in Python\"\nsubtitle: Making life easy to do some serious hypothesis testing in python. \n\ndescription: \"A simple code to run your hypothesis test.\"\n\n# Enable CC licence appendix\nlicense: \"CC BY\"\n\n# Default author\nauthor:\n  - name: Jitin Kapila\n    url: https://www.jitinkapila.com\n\n# Default fields for citation\ncitation: true\n\n# date\ndate: \"2021-08-10\"\n\n# format\nformat: \n  html:\n    toc: true\n    code-fold: true\n    html-math-method: 'webtex'\n    fig-cap-location: bottom\n    cap-location: bottom\n    \nexecute:\n  eval: false\n  echo: true\n  warning: false\n\n# title-block-banner: images/banner.jpeg\ntitle-block-banner: true\nimage: TukeyHSD.png\n\n# category and keywords\ncategories: [eda, hypothesis, analysis, python]\ntags:\n    - hypothesis\n    - python\n    - eda\nkeywords: [anova, hypothesis, python, tukeyhsd, analysis, tests, datascience]\n\nfilters:\n   - lightbox\nlightbox: auto\n---\n\n# Overview\n\nAll the practioners of data science always hit one giant thing to do with data and you know it well its *EDA -Exploratory Data Analysis*.\nThis word *EDA*[^1] was coined by Tukey himself in his seminal book publised in 1983. But do you think that before that *EDA* dosen't exsisted ?  \n\n\n[^1]: Emerson, J. D., & Hoaglin, D. C. (1983). Stem-and-leaf displays. In D. C. Hoaglin, F. Mosteller, & J. W. Tukey (Eds.) Understanding Robust and Exploratory Data Analysis, pp. 7â€“32. New York: Wiley. [Book is here.](https://www.wiley.com/en-in/Understanding+Robust+and+Exploratory+Data+Analysis-p-9780471384915)\n\n\nWell glad you thought. Before that all were doing what is called as *_Hypothesis Tesing_*. Yes, before this the race was majorly to fit the data and make most unbiased and robust estimate. But remember one thing when you talk about *Hypothesis Testing* it was always and majorly would be related to *RCTs \n(Randomized Controlled Trials)* a.k.a Randomized Clinical Trials and is _Gold Standard_ of data.  \n\n\n</br>\n\n:::{.callout-note collapse=\"true\"}\n## \"More on RCTs and ODs\"\n\nNow let me now not hijack the discussion to what is *RCTs* and *Observational Data (ODs)* as it is more of _Philosphical Reasoning_ rather than other quality of data, but essentially what we are trying to find is that can we by, using stats, identify *interesting patterns* in data. \n\nThe only thing happens wit RCT data is that we tend to believe these intresting patterns coincide with some sort of _'Cause-Effect'_  kind of relationship. But essentially due to bia nature of ODs, we certainly cant conclude this. And hence, can only find _intresting_ patterns.\n:::\n\nLets move on. The big question is, for whatever reason you are doing _HT_ , you are doing it for finding _something intresting_. And that something intresting is usually found by using *_Post-Hoc Tests_*. Now there are variety of _Post-Hocs_ available but what is more know and hence easily found to be implemented in _Tukey's HSD_.\n\nSo lets directly jump to how to follow this procedure. We'll be using `bioinfokit` for this, as it is much simpler wrapper around whats impelmented in `statsmodels`.\n\n# Give me \"The Code\"\n\nHere is the code for running and analyzing your hypothesis tests.\n\n:::{.column-body-outset}\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nfrom bioinfokit import analys\n\nimport numpy as np\nfrom scipy import stats\n\n\n# Anova test code\ndef do_anova_test(df, res_var, xfac_var, anova_model,ss_typ=3,\n\t\t\t\t  effectsize='n2',result_full=False,add_res=False):\n    \"\"\"\n    Do all sequential anova tests\n    \n    Step 1) Leven's/ bartellet test for checking weather variance is homogenous or not\n    Step 2) Main ANOVA/ANCOVA test\n    Step 3) Tukey's HSD for individual combinations\n    \n    :param df: Pandas DataFrame holding all the columns\n    :param res_var: Variable for which we are checking ANOVA\n    :param xfac_var: Grouping Variables for which we want to do the comparisions\n    :param anova_model: SM forula for the model. This is life savour to make all things work\n    :param result_full: To provide all the results of intermediate steps\n    \n    \"\"\"\n    \n    class KeyResults:\n        \"\"\"\n        A basic class to hold all the results\n        \"\"\"\n        \n        def __init__(self,result_full):\n            self.keys = []\n            self.result_full = result_full\n        \n        def add_result(self,name,result):\n            if name == 'tukeyhsd':\n                self.keys.append(name)\n                setattr(self, name, result)\n            elif self.result_full:\n                self.keys.append(name)\n                setattr(self, name, result)\n            \n    results = KeyResults(result_full)\n    \n    # initiallize stat method\n    res = analys.stat()\n    \n    # doing levens test\n    res.levene(df=df, res_var=res_var,xfac_var=xfac_var)\n    print('\\nLeven\\'s Test Result:')\n    print(res.levene_summary)\n    results.add_result('levene',res.levene_summary)\n\n    # doing bartlett test\n    res.bartlett(df=df, res_var=res_var,xfac_var=xfac_var)\n    print('\\nBartlett\\'s Test Result:')\n    print(res.bartlett_summary)\n    results.add_result('bartlett',res.bartlett_summary)\n    \n    # doing anova / ancova\n    res.anova_stat(df=df, res_var=res_var, anova_model=anova_model,ss_typ=ss_typ)\n    aov_res = res.anova_summary\n    \n    # Add effect sizes\n    if effectsize == \"n2\":\n        all_effsize = (aov_res['sum_sq'] / aov_res['sum_sq'].sum()).to_numpy()\n        all_effsize[-1] = np.nan\n    else:\n        ss_resid = aov_res['sum_sq'].iloc[-1]\n        all_effsize = aov_res['sum_sq'].apply(lambda x: x / (x + ss_resid)).to_numpy()\n        all_effsize[-1] = np.nan\n    aov_res[effectsize] = all_effsize\n    #aov_res['bw_'] = res.anova_model_out.params.iloc[-1]\n    aov_res = aov_res.round(4)\n    \n    # printing results\n    print('\\nANOVA\\ANCOVA Test Result:')\n    print(aov_res)\n    results.add_result('anova',res.anova_summary.round(4))\n    results.add_result('anova_model',res.anova_model_out)\n    \n    # doing tukey's hsd top compare the groups\n    res.tukey_hsd(df=df, res_var=res_var,xfac_var=xfac_var, anova_model=anova_model,ss_typ=ss_typ)\n    print('\\nTukey HSD Result:')\n    print(res.tukey_summary.round(4))\n    results.add_result('tukeyhsd',res.tukey_summary.round(4))\n    \n    # add all result componets again if needed \n    if add_res:\n        results.add_result('allresult',res)\n    \n    return results\n```\n:::\n\n\n:::\n\nAnd here is one to make it presentableto audience.\n\n:::{.column-body-outset}\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.style.use('seaborn-bright')\n\ndef plot_hsd(hsdres,p_cutoff=0.05,title=None,ax=None,figsize=(10,7)):\n     \"\"\"\n     Do plotting of tukeyhsd results\n    \n  \n    :param hsdres: 'tukeyhsd' result form the do_anova_test function\n    :param p_cutoff: Cutoff at which we get say a combination is significant\n    :param title: Title of the plot\n    :param ax: Define or get the matplotlib axes\n    :param figsize: Mention Figure size to draw\n    \n    \"\"\"\n\n    if ax is None:\n        fig,axp = plt.subplots(figsize=figsize)\n    else:\n        axp = ax\n    \n    # helper func\n    p_ind = lambda x : '' if x > 0.1 else ('+' if x > 0.05 else ('*' if x > 0.01 else ('**' if x >0.001 else '***')))\n    label_gen  = lambda x: f\"${x[0]} - {x[1]}\\ |\\ p:{x[2]:0.2f}{p_ind(x[2]):5s}$\"\n    \n    #setting values\n    mask = hsdres['p-value'] <= p_cutoff\n    yticklabs = hsdres[['group1','group2','p-value']].apply(label_gen,axis=1).values\n    ys = np.arange(len(hsdres))\n    \n    # adding plot to axes\n    axp.errorbar(hsdres[~mask]['Diff'],ys[~mask],xerr=np.abs(hsdres[~mask][['Lower',\"Upper\"]]).values.T,\n                fmt='o', color='black', ecolor='lightgray', elinewidth=2, capsize=0)\n    axp.errorbar(hsdres[mask]['Diff'],ys[mask],xerr=np.abs(hsdres[mask][['Lower',\"Upper\"]]).values.T,\n                fmt='o', color='red', ecolor='pink', elinewidth=2, capsize=5)\n    axp.axvline(x=0,linestyle='--',c='skyblue')\n    axp.set_yticks([])\n    (l,u) = axp.get_xlim()\n    axp.set_xlim(l+1.5*l,u)\n    (l,u) = axp.get_xlim()\n    for idx,labs in enumerate(yticklabs):\n        axp.text(l-0.1*l,ys[idx],labs)\n    axp.set_yticklabels([])\n    \n    # finally doing what is needed\n    if ax is None:\n        plt.title('' if title is None else title,fontsize=14)\n        plt.show()\n    else:\n        return axp\n```\n:::\n\n\n:::\n\n\n# What are the results\n\nPheww... Thats too much code right. But that would save a lot of your time in real life. So in reallife you would write code as 3 steps below:\n\n:::{.column-body-outset}\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\n# import libraries\nimport pandas as pd\n\n# Getting car data from UCI\ndf = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data',\n\t\t\t\t sep='\\s+',header=None,\n\t\t\t\t names=['mpg','cylinders','displacement','horsepower','weight',\n\t\t\t\t 'acceleration','model_year','origin','car_name'])\ndf.head()\n\n# Syntax to do anove with validating the assumption, doing test and a post-hoc\nresults = do_anova_test(df=df, res_var='mpg',xfac_var='cylinders', \n                        anova_model='mpg ~ C(cylinders)+C(origin)+C(cylinders):C(origin)',\n                        ss_typ=3, result_full=True)\n\n# Numbers are clumsy for most. Making more interpretable plot on above results.\nplot_hsd(results.tukeyhsd.sort_values('Diff'), title=\"Tukey HSD resutls Anova of MPG ~ Cylinder\")\n```\n:::\n\n\n:::\n\nResults form the `do_anova_test`\n\n<br>\n\n:::{.panel-center .column-body-outset}\n## Results\n\n```{}\nLevens Test Result:\n                 Parameter    Value\n0      Test statistics (W)  14.5856\n1  Degrees of freedom (Df)   4.0000\n2                  p value   0.0000\n\nBartletts Test Result:\n                 Parameter    Value\n0      Test statistics (T)  61.2143\n1  Degrees of freedom (Df)   4.0000\n2                  p value   0.0000\n\nANOVA\\ANCOVA Test Result:\n                           df     sum_sq    mean_sq         F  PR(>F)      n2\nIntercept                 1.0  6195.1701  6195.1701  296.3452  0.0000  0.2727\nC(cylinders)              4.0  7574.5864  1893.6466   90.5824  0.0000  0.3334\nC(origin)                 2.0   241.0703   120.5351    5.7658  0.0034  0.0106\nC(cylinders):C(origin)    8.0   577.4821    72.1853    3.4530  0.0046  0.0254\nResidual                389.0  8132.1404    20.9052       NaN     NaN     NaN\n\nTukey HSD Result:\n   group1  group2     Diff    Lower    Upper  q-value  p-value\n0       8       4  14.3237  12.8090  15.8383  36.6527   0.0010\n1       8       6   5.0226   3.1804   6.8648  10.5671   0.0010\n2       8       3   5.5869  -0.7990  11.9728   3.3909   0.1183\n3       8       5  12.4036   5.0643  19.7428   6.5503   0.0010\n4       4       6   9.3011   7.6765  10.9256  22.1910   0.0010\n5       4       3   8.7368   2.4102  15.0633   5.3524   0.0017\n6       4       5   1.9201  -5.3676   9.2078   1.0212   0.9000\n7       6       3   0.5643  -5.8486   6.9772   0.3410   0.9000\n8       6       5   7.3810   0.0182  14.7437   3.8854   0.0491\n9       3       5   6.8167  -2.7539  16.3873   2.7606   0.2919\n```\n<br>\n:::\n\n<br>\nResults form the `plot_hsd`\n\n![](TukeyHSD.png)\n\n</br>\n\nPlots look good with 'p-values'. \n\n# Conclusion  \n  \nThings to keep in mind before you do any hypothesis testing.\n\n>Since we applied the above to a *_Non RCT_* we cannot conclude that Difference in mpg based on cylinder is huge specially as number of cylinders goes up.\n>But this statement might not be as explicit as might be apperiang from plot. Unless you have a strong believe that the data follows with rules and assumptions of RCTs,\n>we should be only seeking *intresting* as in *associated* results and not *cause-effet* resluts.\n\nHope this give you kickstart to find you intresting patterns. Happy Learning! \n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}